<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Painting 3D Models with AI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 40px;
            background: #f4f4f4;
            color: #333;
        }
        h1 {
            color: #0056b3;
        }
        ul {
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        li {
            margin-bottom: 10px;
            font-size: 16px;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1># Painting-3D-models-using-Generative-AI</h1>
    <p>Hi, this is a project I did in the spring semester of 2024.</p>
    <p>I leveraged generative AI models to paint 3D models.</p>
    <p>I used Google Colab, PyTorch3D, Stable Diffusion, and ControlNet from HuggingFace to perform the following tasks:</p>
    <ul>
        <li>Rendered a 3D mesh of a cow with its texture.</li>
        <li>Replaced the cow's texture with a different PNG image.</li>
        <li>Given prompt and texture image as inputs, generated new texture images using Stable Diffusion and ControlNet from HuggingFace.</li>
        <li>Rendered the 3D mesh of the cow with the AI-generated texture images.</li>
        <li>Used ControlNet with prompt and 2D rendered images as inputs, instead of prompt and texture image. This led to better AI-generated images.</li>
        <li>Developed algorithm to paint 3D object given AI-generated 2D image from the last step.</li>
    </ul>
    <p>Check out the source code for the results!</p>
</body>
</html>
